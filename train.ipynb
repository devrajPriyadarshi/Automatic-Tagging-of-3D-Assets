{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/devrajpriyadarshi/assesttag?scriptVersionId=102777609\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Point cloud classification with PointNet","metadata":{"id":"z3UCJtYYkSDO"}},{"cell_type":"code","source":"!pip install trimesh","metadata":{"id":"36gsMjldklgA","outputId":"5223b216-5197-4222-aec9-8afbbea4c56f","execution":{"iopub.status.busy":"2022-07-29T08:57:30.602469Z","iopub.execute_input":"2022-07-29T08:57:30.603031Z","iopub.status.idle":"2022-07-29T08:57:43.501034Z","shell.execute_reply.started":"2022-07-29T08:57:30.602915Z","shell.execute_reply":"2022-07-29T08:57:43.49986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\nimport glob\nimport trimesh\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom matplotlib import pyplot as plt\n\ntf.random.set_seed(1234)\n","metadata":{"id":"dvjxlaD1kSDS","execution":{"iopub.status.busy":"2022-07-29T08:57:43.503262Z","iopub.execute_input":"2022-07-29T08:57:43.503642Z","iopub.status.idle":"2022-07-29T08:57:49.172646Z","shell.execute_reply.started":"2022-07-29T08:57:43.503604Z","shell.execute_reply":"2022-07-29T08:57:49.171603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load dataset\n\nWe use the ModelNet10 model dataset, the smaller 10 class version of the ModelNet40\ndataset:\n","metadata":{"id":"z2Jlz9YVkSDT"}},{"cell_type":"code","source":"DATA_DIR = tf.keras.utils.get_file(\n    \"modelnet.zip\",\n    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\n    extract=True,\n)\nDATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet40\")\n","metadata":{"id":"Z0wYiOIrkSDU","outputId":"4751ddf2-da0b-4180-e610-9f18842c32b3","execution":{"iopub.status.busy":"2022-07-29T08:57:49.176352Z","iopub.execute_input":"2022-07-29T08:57:49.177392Z","iopub.status.idle":"2022-07-29T08:58:19.206427Z","shell.execute_reply.started":"2022-07-29T08:57:49.177348Z","shell.execute_reply":"2022-07-29T08:58:19.205101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can use the `trimesh` package to read and visualize the `.off` mesh files.\n","metadata":{"id":"Aq_MvEGjkSDU"}},{"cell_type":"code","source":"mesh = trimesh.load(os.path.join(DATA_DIR, \"chair/train/chair_0001.off\"))\nmesh.show()\n","metadata":{"id":"jzSh3s3FkSDV","outputId":"16744a3b-0533-489a-8fa4-76823f4e3232","execution":{"iopub.status.busy":"2022-07-29T08:58:19.209159Z","iopub.execute_input":"2022-07-29T08:58:19.209775Z","iopub.status.idle":"2022-07-29T08:58:19.274097Z","shell.execute_reply.started":"2022-07-29T08:58:19.209737Z","shell.execute_reply":"2022-07-29T08:58:19.273061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To convert a mesh file to a point cloud we first need to sample points on the mesh\nsurface. `.sample()` performs a unifrom random sampling. Here we sample at 2048 locations\nand visualize in `matplotlib`.\n","metadata":{"id":"avxv_qz9kSDX"}},{"cell_type":"code","source":"points = mesh.sample(2048)\n\nfig = plt.figure(figsize=(5, 5))\nax = fig.add_subplot(111, projection=\"3d\")\nax.scatter(points[:, 0], points[:, 1], points[:, 2])\nax.set_axis_off()\nplt.show()\n","metadata":{"id":"jscGW16PkSDY","outputId":"f56756ee-a9cc-4df7-aec1-9807b33f3fdc","execution":{"iopub.status.busy":"2022-07-29T08:58:19.275231Z","iopub.execute_input":"2022-07-29T08:58:19.275653Z","iopub.status.idle":"2022-07-29T08:58:20.836933Z","shell.execute_reply.started":"2022-07-29T08:58:19.275606Z","shell.execute_reply":"2022-07-29T08:58:20.833631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef parse_dataset(num_points=2048):\n\n    train_points = []\n    train_labels = []\n    test_points = []\n    test_labels = []\n    class_map = {}\n    folders = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\n\n    for i, folder in enumerate(folders):\n        print(\"processing class: {}\".format(os.path.basename(folder)))\n        # store folder name with ID so we can retrieve later\n        class_map[i] = folder.split(\"/\")[-1]\n        # gather all files\n        train_files = glob.glob(os.path.join(folder, \"train/*\"))\n        test_files = glob.glob(os.path.join(folder, \"test/*\"))\n\n        for f in train_files:\n            train_points.append(trimesh.load(f).sample(num_points))\n            train_labels.append(i)\n\n        for f in test_files:\n            test_points.append(trimesh.load(f).sample(num_points))\n            test_labels.append(i)\n\n    return (\n        np.array(train_points),\n        np.array(test_points),\n        np.array(train_labels),\n        np.array(test_labels),\n        class_map,\n    )\n\n","metadata":{"id":"i0dieQX6kSDZ","execution":{"iopub.status.busy":"2022-07-29T08:58:20.83899Z","iopub.execute_input":"2022-07-29T08:58:20.839974Z","iopub.status.idle":"2022-07-29T08:58:20.856627Z","shell.execute_reply.started":"2022-07-29T08:58:20.839933Z","shell.execute_reply":"2022-07-29T08:58:20.854937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_POINTS = 2048\nNUM_CLASSES = 10\nBATCH_SIZE = 32\n\ntrain_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(\n    NUM_POINTS\n)\n","metadata":{"id":"SsWBtNRnkSDa","outputId":"ac98a3b2-90e5-493d-d6d9-90c42eea692c","execution":{"iopub.status.busy":"2022-07-29T08:58:20.859312Z","iopub.execute_input":"2022-07-29T08:58:20.862338Z","iopub.status.idle":"2022-07-29T09:06:29.975963Z","shell.execute_reply.started":"2022-07-29T08:58:20.862301Z","shell.execute_reply":"2022-07-29T09:06:29.974772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef augment(points, label):\n    # jitter points\n    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n    # shuffle points\n    points = tf.random.shuffle(points)\n    return points, label\n\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_points, test_labels))\n\ntrain_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\ntest_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)\n","metadata":{"id":"YPbncWQNkSDb","execution":{"iopub.status.busy":"2022-07-29T09:06:29.977636Z","iopub.execute_input":"2022-07-29T09:06:29.979573Z","iopub.status.idle":"2022-07-29T09:06:33.224998Z","shell.execute_reply.started":"2022-07-29T09:06:29.979531Z","shell.execute_reply":"2022-07-29T09:06:33.224059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef conv_bn(x, filters):\n    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n    x = layers.BatchNormalization(momentum=0.0)(x)\n    return layers.Activation(\"relu\")(x)\n\n\ndef dense_bn(x, filters):\n    x = layers.Dense(filters)(x)\n    x = layers.BatchNormalization(momentum=0.0)(x)\n    return layers.Activation(\"relu\")(x)\n\n","metadata":{"id":"Rxj34t20kSDc","execution":{"iopub.status.busy":"2022-07-29T09:06:33.226555Z","iopub.execute_input":"2022-07-29T09:06:33.226885Z","iopub.status.idle":"2022-07-29T09:06:33.234548Z","shell.execute_reply.started":"2022-07-29T09:06:33.226852Z","shell.execute_reply":"2022-07-29T09:06:33.233488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PointNet consists of two core components. The primary MLP network, and the transformer\nnet (T-net). The T-net aims to learn an affine transformation matrix by its own mini\nnetwork. The T-net is used twice. The first time to transform the input features (n, 3)\ninto a canonical representation. The second is an affine transformation for alignment in\nfeature space (n, 3). As per the original paper we constrain the transformation to be\nclose to an orthogonal matrix (i.e. ||X*X^T - I|| = 0).\n","metadata":{"id":"SRSwp1YAkSDc"}},{"cell_type":"code","source":"\nclass OrthogonalRegularizer(keras.regularizers.Regularizer):\n    def __init__(self, num_features, l2reg=0.001):\n        self.num_features = num_features\n        self.l2reg = l2reg\n        self.eye = tf.eye(num_features)\n\n    def __call__(self, x):\n        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n        xxt = tf.tensordot(x, x, axes=(2, 2))\n        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n\n    def get_config(self):\n        return {  'num_features': self.num_features,\n                  'l2reg': self.l2reg\n                }\n\n","metadata":{"id":"aFVPZ9NUkSDd","execution":{"iopub.status.busy":"2022-07-29T09:06:33.23892Z","iopub.execute_input":"2022-07-29T09:06:33.239229Z","iopub.status.idle":"2022-07-29T09:06:33.248553Z","shell.execute_reply.started":"2022-07-29T09:06:33.239204Z","shell.execute_reply":"2022-07-29T09:06:33.247695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef tnet(inputs, num_features):\n\n    # Initalise bias as the indentity matrix\n    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n    reg = OrthogonalRegularizer(num_features)\n\n    x = conv_bn(inputs, 32)\n    x = conv_bn(x, 64)\n    x = conv_bn(x, 512)\n    x = layers.GlobalMaxPooling1D()(x)\n    x = dense_bn(x, 256)\n    x = dense_bn(x, 128)\n    x = layers.Dense(\n        num_features * num_features,\n        kernel_initializer=\"zeros\",\n        bias_initializer=bias,\n        activity_regularizer=reg,\n    )(x)\n    feat_T = layers.Reshape((num_features, num_features))(x)\n    # Apply affine transformation to input features\n    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n\n","metadata":{"id":"xAMLPmzGkSDd","execution":{"iopub.status.busy":"2022-07-29T09:06:33.249796Z","iopub.execute_input":"2022-07-29T09:06:33.250706Z","iopub.status.idle":"2022-07-29T09:06:33.259568Z","shell.execute_reply.started":"2022-07-29T09:06:33.250671Z","shell.execute_reply":"2022-07-29T09:06:33.258637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = keras.Input(shape=(NUM_POINTS, 3))\n\nx = tnet(inputs, 3)\nx = conv_bn(x, 32)\nx = conv_bn(x, 32)\nx = tnet(x, 32)\nx = conv_bn(x, 32)\nx = conv_bn(x, 64)\nx = conv_bn(x, 512)\nx = layers.GlobalMaxPooling1D()(x)\nx = dense_bn(x, 256)\nx = layers.Dropout(0.3)(x)\nx = dense_bn(x, 128)\nx = layers.Dropout(0.3)(x)\n\noutputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\nmodel.summary()\n","metadata":{"id":"PBEeozHAkSDf","execution":{"iopub.status.busy":"2022-07-29T09:06:33.260892Z","iopub.execute_input":"2022-07-29T09:06:33.261298Z","iopub.status.idle":"2022-07-29T09:06:33.732065Z","shell.execute_reply.started":"2022-07-29T09:06:33.261265Z","shell.execute_reply":"2022-07-29T09:06:33.731154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    loss=\"sparse_categorical_crossentropy\",\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    metrics=[\"sparse_categorical_accuracy\"],\n)\n\nmodel.fit(train_dataset, epochs=40, validation_data=test_dataset)\n","metadata":{"id":"tBUvkOB9kSDg","execution":{"iopub.status.busy":"2022-07-29T09:07:52.123773Z","iopub.execute_input":"2022-07-29T09:07:52.124346Z","iopub.status.idle":"2022-07-29T09:18:46.91808Z","shell.execute_reply.started":"2022-07-29T09:07:52.124304Z","shell.execute_reply":"2022-07-29T09:18:46.917179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize predictions\n\nWe can use matplotlib to visualize our trained model performance.\n","metadata":{"id":"awAdl3AQkSDg"}},{"cell_type":"code","source":"data = test_dataset.take(1)\n\npoints, labels = list(data)[0]\npoints = points[13:13+8, ...]\nlabels = labels[13:13+8, ...]\n\n# run test data through model\npreds = model.predict(points)\npreds = tf.math.argmax(preds, -1)\n\npoints = points.numpy()\n\n# plot points with predicted class and label\nfig = plt.figure(figsize=(15, 10))\nfor i in range(8):\n    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n    ax.set_title(\n        \"pred: {:}, label: {:}\".format(\n            CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n        )\n    )\n    ax.set_axis_off()\nplt.show()\n","metadata":{"id":"GQSsS5IfkSDg","execution":{"iopub.status.busy":"2022-07-29T09:18:46.920625Z","iopub.execute_input":"2022-07-29T09:18:46.920997Z","iopub.status.idle":"2022-07-29T09:18:48.51244Z","shell.execute_reply.started":"2022-07-29T09:18:46.920962Z","shell.execute_reply":"2022-07-29T09:18:48.511524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel.save(\"PointNet_model.tf\")","metadata":{"id":"V3NNlezPrTJl","execution":{"iopub.status.busy":"2022-07-29T09:18:48.513664Z","iopub.execute_input":"2022-07-29T09:18:48.514247Z","iopub.status.idle":"2022-07-29T09:18:58.751874Z","shell.execute_reply.started":"2022-07-29T09:18:48.514211Z","shell.execute_reply":"2022-07-29T09:18:58.750923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predModel = load_model(\"./PointNet_model.tf\", custom_objects={\"OrthogonalRegularizer\":OrthogonalRegularizer})","metadata":{"id":"sxjqtP_ouTmk","outputId":"1d23bb86-a4ef-4c48-c93b-b08ecc20b659","execution":{"iopub.status.busy":"2022-07-29T09:20:39.514889Z","iopub.execute_input":"2022-07-29T09:20:39.515365Z","iopub.status.idle":"2022-07-29T09:20:43.932772Z","shell.execute_reply.started":"2022-07-29T09:20:39.515324Z","shell.execute_reply":"2022-07-29T09:20:43.931822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = test_dataset.take(1)\n\npoints, labels = list(data)[0]\npoints = points[13:13+8, ...]\nlabels = labels[13:13+8, ...]\n\npreds = predModel.predict(points)\npreds = tf.math.argmax(preds, -1)\n\npoints = points.numpy()\n\n# plot points with predicted class and label\nfig = plt.figure(figsize=(15, 10))\nfor i in range(8):\n    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n    ax.set_title(\n        \"pred: {:}, label: {:}\".format(\n            CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n        )\n    )\n    ax.set_axis_off()\nplt.show()\n","metadata":{"id":"cnpPCrvvwGJs","outputId":"d132c92f-1c78-4d74-9940-30c0bd9cf84e","execution":{"iopub.status.busy":"2022-07-29T09:20:51.491977Z","iopub.execute_input":"2022-07-29T09:20:51.492357Z","iopub.status.idle":"2022-07-29T09:20:52.737075Z","shell.execute_reply.started":"2022-07-29T09:20:51.492324Z","shell.execute_reply":"2022-07-29T09:20:52.736094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# os.chdir(r'/kaggle/working')","metadata":{"id":"BXsSppANwV-n","outputId":"4a745213-8542-4113-a8ae-37d22208050d","execution":{"iopub.status.busy":"2022-07-29T09:37:06.30017Z","iopub.execute_input":"2022-07-29T09:37:06.300669Z","iopub.status.idle":"2022-07-29T09:37:06.307736Z","shell.execute_reply.started":"2022-07-29T09:37:06.300639Z","shell.execute_reply":"2022-07-29T09:37:06.306277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"d_Sbc0wM2R6I"},"execution_count":null,"outputs":[]}]}